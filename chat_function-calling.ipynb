{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10199c8-e3c0-43bf-9457-c76e01034ce6",
   "metadata": {},
   "source": [
    "Copyright 2024 Google, LLC. This software is provided as-is,\n",
    "without warranty or representation for any use or purpose. Your\n",
    "use of it is subject to your agreement with Google.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf3fcb-9e41-4105-b89f-64a573b3ffb3",
   "metadata": {},
   "source": [
    "# How to use Function Calling with Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf06d4-3269-4327-9910-d42011859b1a",
   "metadata": {},
   "source": [
    "This notebook outlines how to interact with Vertex AI's Gemini models to call external API's using Function Calling. More info can be found at https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b923f-f712-48ec-a3b6-a3d2a305884f",
   "metadata": {},
   "source": [
    "## Prepare the python development environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcedf7c6-18a7-4294-b8a8-11555a1bde48",
   "metadata": {},
   "source": [
    "First, let's identify any project specific variables to customize this notebook to your GCP environment. Change YOUR_PROJECT_ID with your own GCP project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a33169-d938-4185-8a08-d48cbee56958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id = \"YOUR_PROJECT_ID\"\n",
    "location = \"global\"\n",
    "region = \"us-central1\"\n",
    "key_file = \"key.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae61b6-9b4a-4949-987d-8f5129220759",
   "metadata": {},
   "source": [
    "Install any needed python modules from our requirements.txt file. Most Vertex Workbench environments include all the packages we'll be using, but if you are using an external Jupyter Notebook or require any additional packages for your own needs, you can simply add them to the included requirements.txt file an run the folloiwng commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73c882-f0bb-445a-914e-6702189b8e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d728c-a4a8-4ea7-af59-559c09318512",
   "metadata": {},
   "source": [
    "Now we will import all required modules. For our purpose, we will be utilizing the following:\n",
    "\n",
    "- requests - This module will allow us to interact directly with external REST API's. \n",
    "- FunctionDeclaration - Used to define the function to be called by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55800605-c9b1-40c9-8c12-fb17de2876a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig, Part, Tool, ChatSession, FunctionDeclaration\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "from vertexai.preview.generative_models import grounding, ToolConfig\n",
    "import requests\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157d927-52e9-4f82-bd12-f92264e51b72",
   "metadata": {},
   "source": [
    "## Verify the API key for weatherapi.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb51a6-a938-449b-a4dc-0ce187c87f16",
   "metadata": {},
   "source": [
    "You will need to add your own API key to the key.txt file in order to access the weatherapi endpoint. Please visit https://www.weatherapi.com/ to sign up for a free account and generate your own API key. Once you have your own API key, replace all the text in the key.txt file with your new key.\n",
    "\n",
    "In this example we are using a simple file to store the API key, but you will want to use something like GCP Secret Manager for a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd382c97-e7e3-4cd2-8797-955ac3af3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the API key has been added to the key.txt file\n",
    "weather_api_key = Path(key_file).read_text()\n",
    "\n",
    "if weather_api_key.startswith('Replace all the text') == True:\n",
    "        print('API key has not been added')\n",
    "        raise Exception(f'The {key_file} file does not contain a valid API key. Please visit https://www.weatherapi.com/ to sign up for a free account and generate your own API key.')\n",
    "else:\n",
    "        print(f'The {key_file} file appears to contain a valid API key.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895260a3-8502-4192-9d20-0ba60c0c4cb8",
   "metadata": {},
   "source": [
    "## Define the Gemini Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aecf071-66f4-469e-be8a-405ba77a5f3b",
   "metadata": {},
   "source": [
    "Next we will define the functions to be called by the gemini model. This function will be used to determine the current time based on a specified location provided by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e706b-b025-476b-8af7-9592cdcfb097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_time_func = FunctionDeclaration(\n",
    "    name=\"get_time_func\",\n",
    "    description=\"Get the current time in a given location. Include the area and location, for example 'area: America/New_York', 'Asia/Dubai' and 'Africa/Cairo'\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"Location\"}},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24858e20-84b2-47a9-a099-e7dbd395fb32",
   "metadata": {},
   "source": [
    "Next we'll create a second function to get the current weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d50cd2-becd-46ab-b75b-a58f86918f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_weather_func = FunctionDeclaration(\n",
    "    name=\"get_weather_func\",\n",
    "    description=\"Get the current weather in a given location, for example 'Chicago, New_York, London. Replace any spaces in the name with an underscore, such as New York should be New_York.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"Location\"}},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b59a77-48e6-4f2c-906a-5fb724be7cae",
   "metadata": {},
   "source": [
    "Define a tool to attach the functions to Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19999743-9576-49c0-8b0b-67f56d433948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_tool = Tool(\n",
    "    function_declarations=[get_time_func, get_weather_func],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a3bd5-fc35-41b0-8884-d0331d4bef5e",
   "metadata": {},
   "source": [
    "Initialize the mode, specifying the \"example_tool\" variable linked to the get_time_func and get_weather_func functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18c7a8-c4e8-4002-bf95-36def8fb580f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\n",
    "    \"gemini-1.5-pro-002\",\n",
    "    generation_config=GenerationConfig(temperature=0),\n",
    "    tools=[example_tool],\n",
    "    tool_config=ToolConfig(\n",
    "        function_calling_config=ToolConfig.FunctionCallingConfig(\n",
    "            # ANY mode forces the model to predict a function call\n",
    "            mode=ToolConfig.FunctionCallingConfig.Mode.AUTO,\n",
    "            # Allowed functions to call when the mode is ANY. If empty, any one of\n",
    "            # the provided functions are called.\n",
    "            #allowed_function_names=[\"get_time_func\"],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f2190-d39f-48e0-86d3-1be52f6648f6",
   "metadata": {},
   "source": [
    "## Define a function for determining the function call being used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53210f30-2e94-48d7-a050-0aad3d33decf",
   "metadata": {},
   "source": [
    "By defining a function in python to determine the function call helps keep your code base clean and alloww for easily adding additional function calls in the future. We need to determine which function call is being used to ensure the appropriate parameters are being passed to the API endpoint. As you can see below, the get_weather_func function calls a different backend API and uses different parameters than the get_time_func function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f3329-eb8b-4ed8-861a-0072c1941474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_api(function_name, response, api_key=None):\n",
    "  \"\"\"\n",
    "  Calls an external API based on the provided function name.\n",
    "\n",
    "  Args:\n",
    "    function_name: The name of the function to call.\n",
    "    response: The response object containing function call arguments.\n",
    "    api_key: Optional argument to pass the API key for weather API (required for get_weather_func).\n",
    "\n",
    "  Returns:\n",
    "    A response object with the API response text.\n",
    "  \"\"\"\n",
    "  params = {}\n",
    "\n",
    "  if function_name == 'get_time_func':\n",
    "    for key, value in response.candidates[0].content.parts[0].function_call.args.items():\n",
    "      params[key] = value\n",
    "    url = f\"https://worldtimeapi.org/api/timezone/{params['location']}\"\n",
    "\n",
    "  elif function_name == 'get_weather_func':\n",
    "    # Get the appropriate API key info for the weather API. We are using a simple file for this example, but you will want to use something like GCP Secret Manager for a production environment\n",
    "    weather_api_key = Path(api_key).read_text()\n",
    "    \n",
    "    for key, value in response.candidates[0].content.parts[0].function_call.args.items():\n",
    "      params[key] = value\n",
    "    url = f\"http://api.weatherapi.com/v1/current.json?key={weather_api_key}&q={params['location']}&aqi=no\"\n",
    "\n",
    "  else:\n",
    "    raise ValueError(f\"Invalid function name: {function_name}\")\n",
    "\n",
    "  api_response = requests.get(url, params=params)\n",
    "\n",
    "  # You can optionally include header information as displayed below if required by the api\n",
    "  # api_response = requests.get(url, headers={'X-Api-Key': api_key}, params=params)\n",
    "\n",
    "  # Construct and return the response for the chatbot\n",
    "  response = chat.send_message(\n",
    "      Part.from_function_response(\n",
    "          name=function_name,\n",
    "          response={\n",
    "              \"content\": api_response.text,\n",
    "          },\n",
    "      ),\n",
    "  )\n",
    "\n",
    "  return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f14cac-1180-4acc-abde-161cc3a0e4b2",
   "metadata": {},
   "source": [
    "## Submit a prompt, call the function and return the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad83dc-d496-4de3-87e8-b553dd60d6bd",
   "metadata": {},
   "source": [
    "In this example, we're using the external worldtimeapi.org api to find the current time in a specific timezone based on a specified area. The supported areas can be listed using the following command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04422a0-cb6b-464a-8650-7a610a78c703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get('http://worldtimeapi.org/api/timezone')\n",
    "supported_areas = response.json()\n",
    "\n",
    "for area in supported_areas:\n",
    "    print(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e77226-83d5-4086-a1c1-d551e888158f",
   "metadata": {},
   "source": [
    "Define a request to get the current time in Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437251ea-efeb-4cb9-b586-daf621668724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"What time is it in San Francisco?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04af84f-762b-4e03-a77c-fd91b8548350",
   "metadata": {},
   "source": [
    "Submit the prompt and print the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084a3c9-f343-4a8c-a184-12d320fd01f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = chat.send_message(prompt)\n",
    "\n",
    "#--- Uncomment to see the full response structure\n",
    "#print(response.candidates[0].content.parts[0])\n",
    "\n",
    "#-- If the response includes the \"function_call\" attribute, capture the function name, call the external API, and return the response.\n",
    "if response.candidates[0].content.parts[0].function_call:\n",
    "    function_name = response.candidates[0].content.parts[0].function_call.name\n",
    "    response = call_api(function_name, response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9e0bb-96af-4419-b8c9-64732def1392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Print the text section of the response which includes the current time.\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919d4ce-ff37-49a0-b778-cd0a1b32b5d6",
   "metadata": {},
   "source": [
    "Now let's use the get_weather_func function to get the current weather condition. Notice how we are not specifying the location. Instead we are using the existing context of our chat session to infer the location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf513d-03d5-43fb-b64a-cddab48496b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What's the weather like there?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234eaa1c-cfb5-458f-b55d-a5feb1b77678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = chat.send_message(prompt)\n",
    "\n",
    "#print(response.candidates[0].content.parts[0])\n",
    "\n",
    "if response.candidates[0].content.parts[0].function_call:\n",
    "    function_name = response.candidates[0].content.parts[0].function_call.name\n",
    "    response = call_api(function_name, response, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ba6bf-a48d-4c19-b1eb-b3fcad540374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52bcf30-6b54-47e2-802a-68d78d542e2b",
   "metadata": {},
   "source": [
    "Now let's ask the model a simple question that will not use either of the function calls, but is still based on the context of this conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22e702-4c51-49ce-a306-d086d16c1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What color is the sky?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839fc927-3dbb-4e0b-b709-6291ddd68455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = chat.send_message(prompt)\n",
    "\n",
    "if response.candidates[0].content.parts[0].function_call:\n",
    "    function_name = response.candidates[0].content.parts[0].function_call.name\n",
    "    response = call_api(function_name, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25939f0-2b75-43f8-bce3-e4a5eac5b944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc2961-6466-4a91-adbe-c06c4c607648",
   "metadata": {
    "tags": []
   },
   "source": [
    "Lastly we will ask about an unrelated topic to verify the model is not solely bound to the grounding data provided by the functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7ab7e-8413-4341-a602-d4ad447dafa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Why do thunderstorms form?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bbbfe-8ade-47dd-a2db-75bf71d9a1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = chat.send_message(prompt)\n",
    "\n",
    "if response.candidates[0].content.parts[0].function_call:\n",
    "    function_name = response.candidates[0].content.parts[0].function_call.name\n",
    "    response = call_api(function_name, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f88695-1c74-4aef-8371-456860841948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26255596-352f-48e1-b1c3-0561a0731e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
